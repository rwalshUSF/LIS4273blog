{
  "hash": "31a3e3aa43f7092705af6cab181d5cca",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Module 10 Assignment\"\nauthor: \"Robert Walsh\"\nimage: \"multivariate.jpg\"\ndate: \"2025-03-25\"\n---\n\n\n\nAn Exercise in Multivariate Regression!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# LIS4273 - Module 10. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n\n# Question A.\n\n# Conduct ANOVA (analysis of variance) and Regression coefficients to \n# the data from data (\" cystfibr \") database. You can choose any variable \n# you like to interpret.\nlibrary(ISwR)\ndata(\"cystfibr\")\nattach(cystfibr)\n\n#-------------------------------------------------------------------------#\n# A1. In the report, please state the result of coefficients and \n# significance to any variables you like both under ANOVA and multivariate \n# analysis. Please provide a specific interpretation of R results.\n\n# model:\n# 'bmp' as a function of 'age'+'height'+'weight'+'rv'+'frc'+'tlc'+'pemax'\nbmpModelOne<-lm(bmp~age+height+weight+rv+frc+tlc+pemax,data=cystfibr)\n# The Coefficients:\nbmpModelOne\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = bmp ~ age + height + weight + rv + frc + tlc + pemax, \n    data = cystfibr)\n\nCoefficients:\n(Intercept)          age       height       weight           rv          frc  \n  138.94756     -2.34798     -0.34820      1.42015     -0.02505      0.02401  \n        tlc        pemax  \n   -0.15536     -0.06993  \n```\n\n\n:::\n\n```{.r .cell-code}\n# The intercept is 138.94756 \n# Therefore, the estimated body mass percentage of normal would be\n# around 139 if all predictor variables were 0.\n\n# age: indicates that for each increment of 1 in age, a person’s 'bmp' \n# decreases by 2.34798 with all other variables constant.\n\n# height: indicates that for each increment of 1 in height, a person’s 'bmp' \n# decreases by 0.34820 with all other variables constant.\n\n# weight: indicates that for each increment of 1 in weight, a person’s 'bmp' \n# increases by 1.42015 with all other variables constant.\n\n# Summary of the regression model to seek significant relationships\n# among the variables:\nsummary(bmpModelOne)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = bmp ~ age + height + weight + rv + frc + tlc + pemax, \n    data = cystfibr)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.8666 -1.8780 -0.6527  2.4338 11.2400 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 138.94756   18.76512   7.405 1.03e-06 ***\nage          -2.34798    0.62819  -3.738  0.00164 ** \nheight       -0.34820    0.14754  -2.360  0.03049 *  \nweight        1.42015    0.18965   7.488 8.87e-07 ***\nrv           -0.02505    0.03586  -0.699  0.49425    \nfrc           0.02401    0.07976   0.301  0.76705    \ntlc          -0.15536    0.08926  -1.741  0.09983 .  \npemax        -0.06993    0.04332  -1.615  0.12481    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.997 on 17 degrees of freedom\nMultiple R-squared:  0.8773,\tAdjusted R-squared:  0.8267 \nF-statistic: 17.36 on 7 and 17 DF,  p-value: 1.357e-06\n```\n\n\n:::\n\n```{.r .cell-code}\n# This analysis suggests that 'age', 'height', and 'weight' are significant\n# to 'bmp', and that 'rv', 'frc', 'tlc', and 'pemax' could be removed from\n# the model without significantly affecting the dependent variable outcomes &\n# the F-statistic of 17.36 with a p-value of 1.357e-06 suggests that at least\n# one predictor variable is significantly related to the response variable.\n\n#---------------------------------------------------------------------------#\n# ANOVA of the regression model to seek significant relationships\n# among the variables:\nanova(bmpModelOne)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: bmp\n          Df  Sum Sq Mean Sq F value    Pr(>F)    \nage        1  493.63  493.63 19.7681 0.0003543 ***\nheight     1  200.82  200.82  8.0421 0.0114097 *  \nweight     1 2020.55 2020.55 80.9164 7.138e-08 ***\nrv         1  130.04  130.04  5.2078 0.0356384 *  \nfrc        1    0.01    0.01  0.0002 0.9875888    \ntlc        1  124.40  124.40  4.9819 0.0393593 *  \npemax      1   65.09   65.09  2.6068 0.1248148    \nResiduals 17  424.50   24.97                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# This analysis suggests that 'age','height','weight','rv', and 'tlc' are \n# significant to 'bmp' and 'frc' & 'pemax' could be removed from\n# the model without significantly affecting the dependent variable outcomes.\n# The ANOVA table indicates that there is no significant improvement of the\n# model once 'age','height','weight','rv', and 'tlc' are included.\n\n# Perform a joint test to determine if 'frc' & 'pemax' could be removed from\n# the model without significantly affecting the dependent variable outcomes.\nbmpModelTwo<-lm(bmp~age+height+weight+rv+tlc,data=cystfibr)\nanova(bmpModelOne,bmpModelTwo)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: bmp ~ age + height + weight + rv + frc + tlc + pemax\nModel 2: bmp ~ age + height + weight + rv + tlc\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     17 424.50                           \n2     19 512.47 -2   -87.967 1.7614 0.2017\n```\n\n\n:::\n\n```{.r .cell-code}\n# The ANOVA table suggests we can remove 'frc' & 'pemax'.\n# The large p-value 0.2017 provides good evidence that 'model 2' with five\n# predictors fits as well as 'model 1' with seven predictors.\n\n#---------------------------------------------------------------------------#\n\n# Dropping 'pemax' from the analysis may result in losing valuable data\n# Therefore, a Multivariate Multiple Regression will model multiple dependent\n# variables, with a single set of predictor variables.\n\n# model:\n# 'bmp' and 'pemax' as a function of 'age'+'height'+'weight'+'rv'+'frc'+'tlc'\nmlm1<-lm(cbind(cystfibr$bmp,cystfibr$pemax)~age+height+weight+rv+frc+tlc)\n# Summary of the Multivariate Multiple Regression model to seek significant \n# relationships among the variables:\nsummary(mlm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nResponse cystfibr$bmp :\n\nCall:\nlm(formula = `cystfibr$bmp` ~ age + height + weight + rv + frc + \n    tlc)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.8520 -2.8217 -0.0276  2.5375 10.5757 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 135.57876   19.46330   6.966 1.66e-06 ***\nage          -2.32637    0.65548  -3.549  0.00229 ** \nheight       -0.33877    0.15387  -2.202  0.04097 *  \nweight        1.31722    0.18642   7.066 1.37e-06 ***\nrv           -0.04520    0.03508  -1.288  0.21393    \nfrc           0.07106    0.07749   0.917  0.37125    \ntlc          -0.19249    0.09001  -2.139  0.04643 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 18 degrees of freedom\nMultiple R-squared:  0.8585,\tAdjusted R-squared:  0.8113 \nF-statistic:  18.2 on 6 and 18 DF,  p-value: 9.551e-07\n\n\nResponse cystfibr$pemax :\n\nCall:\nlm(formula = `cystfibr$pemax` ~ age + height + weight + rv + \n    frc + tlc)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-41.447 -19.051  -0.572  16.175  41.161 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)  48.1705   101.4776   0.475    0.641\nage          -0.3090     3.4175  -0.090    0.929\nheight       -0.1349     0.8022  -0.168    0.868\nweight        1.4719     0.9719   1.514    0.147\nrv            0.2881     0.1829   1.575    0.133\nfrc          -0.6728     0.4040  -1.665    0.113\ntlc           0.5310     0.4693   1.132    0.273\n\nResidual standard error: 27.19 on 18 degrees of freedom\nMultiple R-squared:  0.504,\tAdjusted R-squared:  0.3387 \nF-statistic: 3.048 on 6 and 18 DF,  p-value: 0.03083\n```\n\n\n:::\n\n```{.r .cell-code}\n# Is a predictor variable jointly contributing to both models?\n\n# The model for Response 'cystfibr$bmp' suggests that at least one \n# predictor variable is significantly related to the response variable.\n# F-statistic:  18.2 & p-value: 9.551e-07\n# 'age','height','weight',and 'tlc' are significant\n\n# The model for Response 'cystfibr$pemax' suggests that at least one \n# predictor variable is significantly related to the response variable.\n# F-statistic: 3.048 & p-value: 0.03083\n# No predictors indicate significance, the p-value: 0.03083 does.\n\n# Determining whether or not to include predictors in a multivariate multiple\n# regression requires the use of multivariate test statistics (Ford, 2024)\n# The easiest way to do this is to use the Anova() function\n# in the car package (Fox and Weisberg, 2011)\nlibrary(car)\nAnova(mlm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nType II MANOVA Tests: Pillai test statistic\n       Df test stat approx F num Df den Df    Pr(>F)    \nage     1   0.45134    6.992      2     17  0.006083 ** \nheight  1   0.24796    2.803      2     17  0.088726 .  \nweight  1   0.79365   32.692      2     17 1.493e-06 ***\nrv      1   0.14568    1.449      2     17  0.262289    \nfrc     1   0.13809    1.362      2     17  0.282776    \ntlc     1   0.20762    2.227      2     17  0.138338    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# The Type II MANOVA Tests suggest 'height','rv','frc',and 'tlc' are\n# jointly insignificant for the two models\n\n# Check to see if a model with just 'age' and 'weight' fits as well as \n# a model with all six predictors.\n# Fit a smaller model and then compare the smaller model to the larger\n# model using the anova() function (Ford, 2024)\nmlm2<-lm(cbind(cystfibr$bmp,cystfibr$pemax)~age+weight)\nanova(mlm1,mlm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: cbind(cystfibr$bmp, cystfibr$pemax) ~ age + height + weight + \n    rv + frc + tlc\nModel 2: cbind(cystfibr$bmp, cystfibr$pemax) ~ age + weight\n  Res.Df Df Gen.var.  Pillai approx F num Df den Df Pr(>F)\n1     18      132.05                                      \n2     22  4   154.48 0.56897   1.7892      8     36 0.1116\n```\n\n\n:::\n\n```{.r .cell-code}\n# The large p-value 0.1116 provides good evidence that the model with\n# two predictors fits as well as the model with six predictors.\n\n\n#------------------------------------------------------------------------#\n\n# Question B.\n\n# The secher data(\"secher\") are best analyzed after log-transforming birth\n# weight as well as the abdominal and biparietal diameters. Fit a prediction\n# weight as well as abdominal and biparietal diameters.\ndata(\"secher\")\nattach(secher)\n# Fit linear regression for 'bwt' using the log transformed 'ad'\n# Model with only abdominal diameter:\nmodel_ad<-lm(log(bwt)~I(log(ad)),data=secher)\nsummary(model_ad)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log(bwt) ~ I(log(ad)), data = secher)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.58560 -0.06609  0.00184  0.07479  0.48435 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -2.4446     0.5103  -4.791 5.49e-06 ***\nI(log(ad))    2.2365     0.1105  20.238  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1275 on 105 degrees of freedom\nMultiple R-squared:  0.7959,\tAdjusted R-squared:  0.794 \nF-statistic: 409.6 on 1 and 105 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Fit linear regression for 'bwt' using the log transformed 'bpd'\n# Model with only biparietal diameter:\nmodel_bpd<-lm(log(bwt)~I(log(bpd)),data=secher)\nsummary(model_bpd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log(bwt) ~ I(log(bpd)), data = secher)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.36478 -0.09725  0.01251  0.07703  0.51154 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -7.0862     0.9062  -7.819 4.35e-12 ***\nI(log(bpd))   3.3320     0.2017  16.516  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1488 on 105 degrees of freedom\nMultiple R-squared:  0.7221,\tAdjusted R-squared:  0.7194 \nF-statistic: 272.8 on 1 and 105 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Fit linear regression for 'bwt' using the log transformed 'ad' + 'bpd'\n# Combine both models:\nmodel_combined<-lm(log(bwt)~I(log(ad))+I(log(bpd)),data=secher)\nsummary(model_combined)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log(bwt) ~ I(log(ad)) + I(log(bpd)), data = secher)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.35074 -0.06741 -0.00792  0.05750  0.36360 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -5.8615     0.6617  -8.859 2.36e-14 ***\nI(log(ad))    1.4667     0.1467   9.998  < 2e-16 ***\nI(log(bpd))   1.5519     0.2294   6.764 8.09e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1068 on 104 degrees of freedom\nMultiple R-squared:  0.8583,\tAdjusted R-squared:  0.8556 \nF-statistic: 314.9 on 2 and 104 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# For a prediction equation for birth weight.\n\n# birthweight = -5.8615 + 1.4667(abdominal) + 1.5519(biparietal)\n\n# B1. How much is gained by using both diameters in a prediction equation?\nr_sq_model_ad<-summary(model_ad)$r.squared\nr_sq_model_bpd<-summary(model_bpd)$r.squared\nr_sq_model_combined<-summary(model_combined)$r.squared\nr_sq_gain<-r_sq_model_combined - mean(c(r_sq_model_ad,r_sq_model_bpd))\ncat(\"The Avg. Gain in R-sq is approx:\", r_sq_gain, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThe Avg. Gain in R-sq is approx: 0.09928108 \n```\n\n\n:::\n\n```{.r .cell-code}\n# The sum of the two regression coefficients is almost identical and \n# equal to 3.\n\n# B2. Can this be given a nice interpretation to our analysis?\n# Please provide step by step on your analysis and code you use\n# to find out the result. \n\n# The regression coefficients for log(ad) and log(bpd) are approx.(1.5) each.\n# Their sum is approx. (3).\ncat(\"Regression coefficients:\",\"\\n\",\n\"Abdominal diameter:\", coef(model_combined)[2],\"\\n\",\n\"Biparietal diameter:\", coef(model_combined)[3],\"\\n\",\n\"Sum of coefficients:\", coef(model_combined)[2] + coef(model_combined)[3],\"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRegression coefficients: \n Abdominal diameter: 1.466662 \n Biparietal diameter: 1.551943 \n Sum of coefficients: 3.018605 \n```\n\n\n:::\n\n```{.r .cell-code}\n# This suggests that a 1% increase in both abdominal and biparietal diameters \n# is associated with an approximate 3% increase in birth weight.\n\n# Model without log-transformation:\nmodel_reg<-lm(bwt~ad+bpd,data=secher)\n# Predict 'bwt' for 1% increase in both 'ad' & 'bpd'\npredict(model_reg,data.frame(ad=c(95,96),bpd=c(95,96)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       1        2 \n2676.999 2753.895 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate percent increase\npercentIncrease<-((2753.895-2676.999)/2676.999)*100\ncat(\"For a 1% increase from 95mm to 96mm in both 'ad' & 'bpd'\nThe 'bwt' gain in grams is approx:\", percentIncrease, \"%\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFor a 1% increase from 95mm to 96mm in both 'ad' & 'bpd'\nThe 'bwt' gain in grams is approx: 2.87247 %\n```\n\n\n:::\n\n```{.r .cell-code}\n# B3. Just an additional question (This will not be graded).\n# When should we consider \"log-transforming\" a dataset?\n# This is a very common practice in data science. \n\ncat(\"When simplifying complex relationships. For example,\nsome relationships between variables might be difficult to interpret \nin the original scale. Log-transforming could simplify the complex\nrelationships, making them easier to understand and model.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWhen simplifying complex relationships. For example,\nsome relationships between variables might be difficult to interpret \nin the original scale. Log-transforming could simplify the complex\nrelationships, making them easier to understand and model.\n```\n\n\n:::\n\n```{.r .cell-code}\n# References:\n```\n:::\n\n\n\nFox, J and Weisberg, S (2011). An {R} Companion to Applied Regression, Second Edition. Thousand Oaks CA: Sage. URL: http://socserv.socsci.mcmaster.ca/jfox/Books/Companion\n\nFord, C (2024). Getting started with Multivariate Multiple Regression with R blog posting. Hosted by the University of Virginia Library.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}