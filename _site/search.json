[
  {
    "objectID": "posts/Welcome/index.html",
    "href": "posts/Welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in my LIS4273 blog. Welcome!"
  },
  {
    "objectID": "posts/Module 7 Assignment/index.html",
    "href": "posts/Module 7 Assignment/index.html",
    "title": "Module 7 Assignment",
    "section": "",
    "text": "An Exercise in Simple and Multiple Regression!\n\n# LIS4273 - Module 7. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n\n# Question A.\n\n# In this assignment's segment, we will use the following regression\n# equation  Y = a + bX +e\n\n# Y is the value of the dependent variable (Y),\n# what is being predicted or explained\n\n# a or Alpha, a constant; equals the value of Y when the value of X=0\n\n# b or Beta, the coefficient of X; the slope of the regression line;\n# how much Y changes for each one-unit change in X.\n\n# X is the value of the Independent variable (X),\n# what is predicting or explaining the value of Y\n\n# e is the error term; the error in predicting the value of Y,\n# given the value of X (it is not displayed in most regression equations).\n\n# The data in this assignment:\nx &lt;- c(16, 17, 13, 18, 12, 14, 19, 11, 11, 10)\ny &lt;- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)\n\n# A1. Define the relationship model between the independent\n# and the dependent variable.\n\n# 'x' is the value of the Independent variable (X),\n# what is predicting or explaining the value of 'y'.\n# 'y' is the value of the dependent variable (Y),\n# what is being predicted or explained.\n\n# To model the relationship between how one variable affects the other:\nmodel.x.y&lt;-lm(y~x,)\n# Create 'model.x.y' object to store results of.....\n# lm(Y~X), linear model: 'y' is predicted by 'x'\n\n# A2. Calculate the coefficients:\n# Print 'model.x.y' object.\nmodel.x.y\n\n\nCall:\nlm(formula = y ~ x)\n\nCoefficients:\n(Intercept)            x  \n     19.206        3.269  \n\n# Question B.\n\n# The following question is posted by Chi Yau (Links to an external site.)\n# the author of  R Tutorial With Bayesian Statistics Using Stan\n# (Links to an external site.) and his blog posting regarding\n# Regression analysis (Links to an external site.).\n\n# Apply the simple linear regression model (see the above formula)\n# for the data set called \"visit\" (see below), and estimate the\n# discharge duration if the waiting time since the last eruption\n# has been 80 minutes.\n\n#  &gt;head(visit) \n#  discharge  waiting \n# 1     3.600      79 \n# 2     1.800      54 \n# 3     3.333      74 \n# 4     2.283      62 \n# 5     4.533      85 \n# 6     2.883      55\n\nvisit&lt;-data.frame(\"discharge\"=c(3.600,1.800,3.333,2.283,4.533,2.883),\n                  \"waiting\"=c(79,54,74,62,85,55))\n\n# Employ the following formula lm(discharge~waiting,data=visit)\n\n# B1. Define the relationship model between the predictor\n# and the response variable.\n\n# The 'predictor' variable predicts the 'response' variable.\n# 'waiting' is the value of the Independent variable (X),\n# what is predicting or explaining the value of 'discharge'.\n# 'discharge' is the value of the dependent variable (Y),\n# what is being predicted or explained.\n\n# To model the relationship between how one variable affects the other:\ndischarge.lm&lt;-lm(discharge~waiting,data=visit)\n# Create 'discharge.lm' object to store results of.....\n# lm(discharge~waiting,data=visit), linear model:\n# 'discharge' is predicted by 'waiting'\n\n# B2. Extract the parameters of the estimated regression equation\n# with the coefficients function.\ncoeffs&lt;-coefficients(discharge.lm)\ncoeffs\n\n(Intercept)     waiting \n-1.53317418  0.06755757 \n\n# B3. Determine the fit of the eruption duration using\n# the estimated regression equation.\n\n# Create 'waitingTime' object and initialize to value of '80'.\nwaitingTime&lt;-80\n# Fit the discharge duration using the estimated regression equation.\ndischargeDuration&lt;-coeffs[1]+coeffs[2]*waitingTime\ndischargeDuration\n\n(Intercept) \n   3.871431 \n\n# Based on the linear regression model, if the waiting time since the\n# last discharge has been 80 minutes, we expect the next discharge duration\n# to last approximately 3.871431 minutes.\n\n# Question C.  Multiple regression\n\n# We will use a very famous datasets in R called mtcars. This dateset\n# was extracted from the 1974 Motor Trend US magazine, and comprises\n# fuel consumption and 10 aspects of automobile design and performance\n# for 32 automobiles (1973--74 models).\n\n# This data frame contain 32 observations on 11 (numeric) variables.\n\n# [, 1] mpg Miles/(US) gallon\n# [, 2] cyl Number of cylinders\n# [, 3] disp    Displacement (cu.in.)\n# [, 4] hp  Gross horsepower\n# [, 5] drat    Rear axle ratio\n# [, 6] wt  Weight (1000 lbs)\n# [, 7] qsec    1/4 mile time\n# [, 8] vs  Engine (0 = V-shaped, 1 = straight)\n# [, 9] am  Transmission (0 = automatic, 1 = manual)\n# [,10] gear    Number of forward gears\n\n# To call mtcars data in R\n# R comes with several built-in data sets, which are generally used\n# as demo data for playing with R functions. One of those datasets\n# build in R is mtcars.\n\n# In this question, we will use 4 of the variables found in mtcars\n# by using the following function\n# input &lt;- mtcars[,c(\"mpg\",\"disp\",\"hp\",\"wt\")]\n\n# C1. Examine the relationship Multi Regression Model as stated above\n# and its Coefficients using 4 different variables from mtcars\n# (mpg, disp, hp and wt).\n# Report on the result and explanation what does the multi regression\n# model and coefficients tell about the data.\ninput &lt;- mtcars[,c(\"mpg\",\"disp\",\"hp\",\"wt\")]\nprint(head(input))\n\n                   mpg disp  hp    wt\nMazda RX4         21.0  160 110 2.620\nMazda RX4 Wag     21.0  160 110 2.875\nDatsun 710        22.8  108  93 2.320\nHornet 4 Drive    21.4  258 110 3.215\nHornet Sportabout 18.7  360 175 3.440\nValiant           18.1  225 105 3.460\n\nlm(formula=mpg~disp+hp+wt,data=input)\n\n\nCall:\nlm(formula = mpg ~ disp + hp + wt, data = input)\n\nCoefficients:\n(Intercept)         disp           hp           wt  \n  37.105505    -0.000937    -0.031157    -3.800891  \n\ncat(\"The relationship multi regression model demonstrates that 'mpg' is \nthe 'response variable' being predicted by 'disp', 'hp', and 'wt' which\nare the 'predictor variables.' What is learned from the coefficients is that\n'disp' and 'hp' have coefficients close to 0 which means that they may relate\nin similar ways. The -3.8 coefficient for 'wt' means that as 'wt' increases,\n'mpg' decreases and as 'mpg' increases, 'wt' decreases. This demonstrates how\neach variable predicts or affects 'mpg' differently and to what magnitude. Each\npredictor variable is individually related to the response variable.\")\n\nThe relationship multi regression model demonstrates that 'mpg' is \nthe 'response variable' being predicted by 'disp', 'hp', and 'wt' which\nare the 'predictor variables.' What is learned from the coefficients is that\n'disp' and 'hp' have coefficients close to 0 which means that they may relate\nin similar ways. The -3.8 coefficient for 'wt' means that as 'wt' increases,\n'mpg' decreases and as 'mpg' increases, 'wt' decreases. This demonstrates how\neach variable predicts or affects 'mpg' differently and to what magnitude. Each\npredictor variable is individually related to the response variable."
  },
  {
    "objectID": "posts/Module 5 Assignment/index.html",
    "href": "posts/Module 5 Assignment/index.html",
    "title": "Module 5 Assignment",
    "section": "",
    "text": "An exercise in Hypothesis Testing & Correlation!\n\n# LIS4273 - Module 5. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n\n# Question A.\n\n# The director of manufacturing at a cookies company needs to determine\n# whether a new machine is able to produce a particular type of cookies\n# according to the manufacturer's specifications, which indicate that\n# cookies should have a mean of 70 and standard deviation of 3.5 pounds.\n# A sample of 49 cookies reveals a sample mean breaking strength\n# of 69.1 pounds.\n\n# A1. State the null and alternative hypothesis :\n\n# Null Hypothesis - Ho: The mean µ = 70\n# New machine is able to produce cookies within spec.\n# Mean breaking strength is equal to 70\n\n# Alt Hypothesis - Ha: The mean µ ≠ 70\n# New machine is not able to produce cookies within spec.\n# Mean breaking strength is not equal to 70\n\n# A2. Is there evidence that the machine is not meeting the manufacturer's\n# specifications for average strength?\n\n# Use a 0.05 level of significance.\nalpha &lt;- 0.05\n# Population Mean = 70\na &lt;- 70\n# Standard Deviation = 3.5\ns &lt;- 3.5\n# Sample Size = 49\nn &lt;- 49\n# Sample Mean = 69.1\nxbar &lt;- 69.1\n# Calculate Test Statistic:\nz &lt;- (xbar-a)/(s/sqrt(n))\nz\n\n[1] -1.8\n\n# Use qnorm() to determine critical values @ 0.05 alpha\n# Two tailed test would identify a 0.025 rejection area on each tail\nz.half.alpha &lt;- qnorm(1-alpha/2)\n# The critical vales are - 1.96 and + 1.96\nz.half.alpha\n\n[1] 1.959964\n\n-z.half.alpha\n\n[1] -1.959964\n\n# Determine if the Test Statistic is in the rejection region.\nz &lt; -z.half.alpha || abs(z) &gt; z.half.alpha\n\n[1] FALSE\n\n# -1.96 &gt; -1.80 &gt; 0 &lt; 1.80 &lt; 1.96\n# The Test Statistic falls between the critical values in the\n# 'do not reject Ho/Null' region. Therefore we can infer\n# that there is evidence that the machine is meeting the manufacturer’s \n# specifications for average strength.\n\n# A3. Compute the p value and interpret its meaning.\n\n# Use pnorm() to calculate the p value using the Test Statistic 'Z'\n# Then multiply the value by two for the two tailed test.\np &lt;- 2*pnorm(z)\n# We get a p value of:\np\n\n[1] 0.07186064\n\n# Test to see if this p value is greater than alpha.\np &gt; alpha\n\n[1] TRUE\n\n# Because the p value is greater than alpha, there is not enough\n# evidence to reject the Null hypothesis - Ho.\n\n# A4. What would be your answer in (A2) if the standard\n# deviation were specified as 1.75 pounds?\n\nalpha &lt;- 0.05\n# Population Mean = 70\na &lt;- 70\n# Standard Deviation = 1.75\ns &lt;- 1.75\n# Sample Size = 49\nn &lt;- 49\n# Sample Mean = 69.1\nxbar &lt;- 69.1\n# Calculate Test Statistic:\nz &lt;- (xbar-a)/(s/sqrt(n))\nz\n\n[1] -3.6\n\n# Use qnorm() to determine critical values @ 0.05 alpha\n# Two tailed test would identify a 0.025 rejection area on each tail\nz.half.alpha &lt;- qnorm(1-alpha/2)\n# The critical vales are - 1.96 and + 1.96\nz.half.alpha\n\n[1] 1.959964\n\n-z.half.alpha\n\n[1] -1.959964\n\n# Determine if the Test Statistic is in the rejection region.\nz &lt; -z.half.alpha || abs(z) &gt; z.half.alpha\n\n[1] TRUE\n\n# -3.60 &gt; -1.96 &gt; 0 &lt; 1.96 &lt; 3.60\n# The Test Statistic falls outside the critical values in the\n# 'reject Ho/Null' region. Therefore we can infer\n# that there is evidence that the machine is not meeting the \n# manufacturer’s specifications for average strength.\n\n# A5. What would be your answer in (A2) if the sample mean were \n# 69 pounds and the standard deviation is 3.5 pounds?\n\nalpha &lt;- 0.05\n# Population Mean = 70\na &lt;- 70\n# Standard Deviation = 3.5\ns &lt;- 3.5\n# Sample Size = 49\nn &lt;- 49\n# Sample Mean = 69\nxbar &lt;- 69\n# Calculate Test Statistic:\nz &lt;- (xbar-a)/(s/sqrt(n))\nz\n\n[1] -2\n\n# Use qnorm() to determine critical values @ 0.05 alpha\n# Two tailed test would identify a 0.025 rejection area on each tail\nz.half.alpha &lt;- qnorm(1-alpha/2)\n# The critical vales are - 1.96 and + 1.96\nz.half.alpha\n\n[1] 1.959964\n\n-z.half.alpha\n\n[1] -1.959964\n\n# Determine if the Test Statistic is in the rejection region.\nz &lt; -z.half.alpha || abs(z) &gt; z.half.alpha\n\n[1] TRUE\n\n# -2 &gt; -1.96 &gt; 0 &lt; 1.96 &lt; 2\n# The Test Statistic falls outside the critical values in the\n# 'reject Ho/Null' region. Therefore we can infer\n# that there is evidence that the machine is not meeting the \n# manufacturer’s specifications for average strength.\n\n\n# Question B. If x̅ = 85, σ = standard deviation = 8, and n=64,\n# set up 95% confidence interval estimate of the population mean μ.\n\n# The 'Zc' Critical Value for a 95% Level of Confidence C = 1.96\nzc &lt;- 1.96\n# Sample Mean = 85\nxbar &lt;- 85\n# Standard Deviation = 8\ns &lt;- 8\n# Sample Size = 64\nn &lt;- 64\n\n# Calculate Upper Confidence Limit value\nxBarPlusE &lt;- xbar + (zc*(s/sqrt(n)))\n# Calculate Upper Confidence Limit value\nxBarMinusE &lt;- xbar - (zc*(s/sqrt(n)))\n# Therefore the 95% confidence interval would be:\nprint(\"(83.04,86.96)\")\n\n[1] \"(83.04,86.96)\"\n\n# There is a 95% probability that the population mean\n# would be in between these two values.\n\n\n# Question C. Given the time spent on assignments each week\n# for the sampled girl group and boy group, respectively,\nlibrary(GGally)\n\nLoading required package: ggplot2\n\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\ngirls_grades &lt;- c(89, 90, 91, 95, 98, 99, 96, 99)\ngirls_time_spend &lt;- c(19, 20, 22, 25, 28, 30, 32, 36)\n\nboys_grades &lt;- c(86, 84, 92, 93, 93, 96, 98, 98)\nboys_time_spend &lt;- c(15, 19, 22, 23, 25, 29, 30, 40)\n\n# Please perform the correlation analysis:\n\n# C1. Calculate the correlation coefficient (Pearson) between\n# time spent and grade for girls' and boys' datasets, respectively.\n\n# The Pearson correlation coefficient between time spent and grade\n# for the Girls' dataset:\nx&lt;-c(girls_grades)\ny&lt;-c(girls_time_spend)\ngirlsData&lt;-data.frame(x,y)\nround(cor(girlsData,method=\"pearson\"),digits=2)\n\n     x    y\nx 1.00 0.91\ny 0.91 1.00\n\n# This result is close to 1 so a strong positive relation is implied.\n\n# The Pearson correlation coefficient between time spent and grade\n# for the Boys' dataset:\nx&lt;-c(boys_grades)\ny&lt;-c(boys_time_spend)\nboysData&lt;-data.frame(x,y)\nround(cor(boysData,method=\"pearson\"),digits=2)\n\n     x    y\nx 1.00 0.86\ny 0.86 1.00\n\n# This result is close to 1 so a strong positive relation is implied.\n\n# C2. Use ggpairs to plot the time spent and grade for\n# girls' and boys' datasets, respectively.\n\n# For the Girls' dataset:\nggpairs(\n  girlsData,\n  upper = list(wrap(\"cor\", size = 5)),\n  diag = list(continuous = \"densityDiag\"),\n)\n\n\n\n\n\n\n\n# For the Boys' dataset:\nggpairs(\n  boysData,\n  upper = list(wrap(\"cor\", size = 5)), \n  diag = list(continuous = \"densityDiag\"),\n)"
  },
  {
    "objectID": "posts/Module 3 Assignment/index.html",
    "href": "posts/Module 3 Assignment/index.html",
    "title": "Module 3 Assignment",
    "section": "",
    "text": "An exercise in descriptive statistics!\nThis was a lot of fun!\n\n# LIS4273 - Module 3. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n#\nlibrary(DescTools)\n# Import the two data sets from .csv file\ndataSets&lt;-read.csv(\"C:/LIS4273blog/Mod3DataSets.csv\",header = TRUE,sep = \",\")\ndataSets\n\n  Set.1 Set.2\n1    10    20\n2     2    12\n3     3    13\n4     2    12\n5     4    14\n6     2    12\n7     5    15\n\n# (A1) For each set, compute the mean, median, \n# and mode under Central Tendency\n#\n# ----------------\n# CENTRAL TENDENCY\n# ----------------\n# Set # 1, Mean:\nmean(dataSets$Set.1)\n\n[1] 4\n\n# Set # 1, Median:\nmedian(dataSets$Set.1)\n\n[1] 3\n\n# Set # 1, Mode:\nMode(dataSets$Set.1)\n\n[1] 2\nattr(,\"freq\")\n[1] 3\n\n# ----------------\n# CENTRAL TENDENCY\n# ----------------\n# Set # 2 Mean:\nmean(dataSets$Set.2)\n\n[1] 14\n\n# Set # 2 Median:\nmedian(dataSets$Set.2)\n\n[1] 13\n\n# Set # 2 Mode:\nMode(dataSets$Set.2)\n\n[1] 12\nattr(,\"freq\")\n[1] 3\n\n# (A2) For each set, compute the range, interquartile, \n# variance, and standard deviation under Variation\n#\n# ---------\n# VARIATION\n# ---------\nset1_minMax&lt;-range(dataSets$Set.1)\n# The Min & Max of Set # 1 are:\nset1_minMax\n\n[1]  2 10\n\nset1_range&lt;-set1_minMax[2]-set1_minMax[1]\n# The Range of Set # 1 is:\nset1_range\n\n[1] 8\n\nquartileSet1&lt;-quantile(dataSets$Set.1)\n# The Quartiles of Set # 1 are:\nquartileSet1\n\n  0%  25%  50%  75% 100% \n 2.0  2.0  3.0  4.5 10.0 \n\ninterQuartileRangeSet1&lt;-as.numeric(quartileSet1[4])-as.numeric(quartileSet1[2])\n# The InterQuartile Range for Set # 1 is:\ninterQuartileRangeSet1\n\n[1] 2.5\n\n# The Variance of Set # 1 is:\nvar(dataSets$Set.1)\n\n[1] 8.333333\n\n# The Standard Deviation of Set # 1 is:\nsd(dataSets$Set.1)\n\n[1] 2.886751\n\n# ---------\n# VARIATION\n# ---------\nset2_minMax&lt;-range(dataSets$Set.2)\n# The Min & Max of Set # 2 are:\nset2_minMax\n\n[1] 12 20\n\nset2_range&lt;-set2_minMax[2]-set2_minMax[1]\n# The Range of Set # 2 is:\nset1_range\n\n[1] 8\n\nquartileSet2&lt;-quantile(dataSets$Set.2)\n# The Quartiles of Set # 2 are:\nquartileSet2\n\n  0%  25%  50%  75% 100% \n12.0 12.0 13.0 14.5 20.0 \n\ninterQuartileRangeSet2&lt;-as.numeric(quartileSet2[4])-as.numeric(quartileSet2[2])\n# The InterQuartile Range for Set # 2 is:\ninterQuartileRangeSet2\n\n[1] 2.5\n\n# The Variance of Set # 2 is:\nvar(dataSets$Set.2)\n\n[1] 8.333333\n\n# The Standard Deviation of Set # 2 is:\nsd(dataSets$Set.2)\n\n[1] 2.886751\n\n# (A3) Compare your results between Set # 1 vs. Set # 2\n# by discussing the differences between the two sets.\n#\n# --------------------\n# SUMMARY / COMPARISON\n# --------------------\n#\ncv1&lt;-(sd(dataSets$Set.1)/mean(dataSets$Set.1))*100\ncv2&lt;-(sd(dataSets$Set.2)/mean(dataSets$Set.2))*100\ncompdf&lt;-data.frame(\"Mean\"=c(mean(dataSets$Set.1),mean(dataSets$Set.2)),\n\"Median\"=c(median(dataSets$Set.1),median(dataSets$Set.2)),\n\"Mode\"=c(Mode(dataSets$Set.1),Mode(dataSets$Set.2)),\n\"Range\"=c(set1_range,set2_range),\n\"Variance\"=c(var(dataSets$Set.1),var(dataSets$Set.2)),\n\"Std Dev\"=c(sd(dataSets$Set.1),sd(dataSets$Set.2)),\n\"CV\"=c(cv1,cv2),\nrow.names = c(\"Set.1\",\"Set.2\"))\ncompdf\n\n      Mean Median Mode Range Variance  Std.Dev       CV\nSet.1    4      3    2     8 8.333333 2.886751 72.16878\nSet.2   14     13   12     8 8.333333 2.886751 20.61965\n\nsummary(dataSets$Set.1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    2.0     2.0     3.0     4.0     4.5    10.0 \n\nsummary(dataSets$Set.2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   12.0    12.0    13.0    14.0    14.5    20.0 \n\n# ------------------------\n# COEFFICIENT OF VARIATION\n# ------------------------\n# Coefficient of variation, as percent:\n# Set # 1:\ncv1\n\n[1] 72.16878\n\n# Set # 2:\ncv2\n\n[1] 20.61965\n\n# Although both sets had an equal range and variance...\n# They had significantly different means.\n# The set of data that has the greatest spread of variance\n# relative to the mean is:\nif (cv1&gt;cv2) {paste(\"Set # 1, Coefficient of Variance = \", cv1, \"VS.\", cv2)\n} else {paste(\"Set # 2, Coefficient of Variance = \", cv2, \"VS.\", cv1)}\n\n[1] \"Set # 1, Coefficient of Variance =  72.1687836487032 VS. 20.6196524710581\""
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": " USF - LIS4273 Advanced Stats - Blog ",
    "section": "",
    "text": "Module 8 Assignment\n\n\n\n\n\n\n\n\n\n\n\nMar 5, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\n\n\n\n\n\n\nModule 7 Assignment\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\n\n\n\n\n\n\nModule 6 Assignment\n\n\n\n\n\n\n\n\n\n\n\nFeb 17, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\n\n\n\n\n\n\nModule 5 Assignment\n\n\n\n\n\n\n\n\n\n\n\nFeb 11, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\n\n\n\n\n\n\nModule 4 Assignment\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\n\n\n\n\n\n\nModule 3 Assignment\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\n\n\n\n\n\n\nModule 2 Assignment\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Robert Walsh",
    "section": "",
    "text": "UNIVERSITY OF SOUTH FLORIDA - SCHOOL OF INFORMATION - LIS4273\nA blog for sharing my class assignments."
  },
  {
    "objectID": "posts/Module 2 Assignment/index.html",
    "href": "posts/Module 2 Assignment/index.html",
    "title": "Module 2 Assignment",
    "section": "",
    "text": "This Function Calculates The Mean!\nHere is how it works!\n\n# LIS4273 - Module 2. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n\n# Create a vector using the c() function\n# and store the results in the 'assignment2' variable/object\n\nassignment2 &lt;- c(6,18,14,22,27,17,22,20,22)\n\n# Create a function named 'myMean' that will\n# accept 'assignment2' as an input variable/argument and then\n# calculate & return the value of the sum of all values in the\n# 'assignment2' vector using the sum() function, and then divide\n# that result by the number of components in the 'assignment2'\n# vector using the length() function. the result is stored in the\n# 'result' variable/object.\n\nmyMean &lt;- function(assignment2) \n{\n  return(sum(assignment2)/length(assignment2))\n}\n\n# print the result as output by calling 'myMean' with \n# 'assignment2' as the argument\n\nresult &lt;- myMean(assignment2)\nresult\n\n[1] 18.66667\n\n# Here is the output!"
  },
  {
    "objectID": "posts/Module 4 Assignment/index.html",
    "href": "posts/Module 4 Assignment/index.html",
    "title": "Module 4 Assignment",
    "section": "",
    "text": "An exercise in probability!\n\n# LIS4273 - Module 4. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n#\ntable1&lt;-data.frame(\"B\"=c(10,20,30),\"B1\"=c(20,40,60),\"Totals\"=c(30,60,90),\nrow.names = c(\"A\",\"A1\",\"Totals\"))\nlibrary(gridExtra)\ngrid.table(table1)\n\n\n\n\n\n\n\n#Question A.\n#Based on Table 1, what is the probability of:\n#A1. Event A ?\nA&lt;-30/90\npaste(\"The probability of event A = \",format(round(A,4)),\"%\")\n\n[1] \"The probability of event A =  0.3333 %\"\n\n#A2. Event B ?\nB&lt;-30/90\npaste(\"The probability of event B = \",format(round(B,4)),\"%\")\n\n[1] \"The probability of event B =  0.3333 %\"\n\n#A3. Event A or B ?\nAorB&lt;-((30/90)+(30/90))-(10/90)\npaste(\"The probability of event A or B = \",format(round(AorB,4)),\"%\")\n\n[1] \"The probability of event A or B =  0.5556 %\"\n\n#A4. P(A or B) = P(A) + P(B)\nAorB == A + B\n\n[1] FALSE\n\n# Question B.\n# In terms of probabilities, we know the following:\n# P( A1 ) = 5/365 =0.0136985 [It rains 5 days out of the year.]\n# P( A2 ) = 360/365 = 0.9863014 [It does not rain 360 days out of the year.]\n# P( B | A1 ) = 0.9 [When it rains, the weatherman predicts rain 90% of the time.]\n# P( B | A2 ) = 0.1 [When it does not rain, the weatherman predicts rain 10% of the time.]\n# We want to know P( A1 | B ), the probability it will rain on the day of Jane's wedding,\n# given a forecast for rain by the weatherman. \n\n# The answer can be determined from Bayes' theorem, as shown below.\n\n# P( A1 | B ) = P( A1 ) P( B | A1 ) / P( A1 ) P( B | A1 ) + P( A2 ) P( B | A2 )\n# P( A1 | B ) = (0.014)(0.9) / [ (0.014)(0.9) + (0.986)(0.1) ]\n# P( A1 | B ) = 0.111\n# Note the somewhat unintuitive result. Even when the weatherman predicts rain,\n# it only rains only about 11% of the time. \n# Despite the weatherman's gloomy prediction, there is a good chance that Jane\n# will not get rained on at her wedding.\n\n# Please answer the following questions:\n# B1. Is this answer True or False ?\nprint(\"TRUE\")\n\n[1] \"TRUE\"\n\n# B2. Please explain why:\ncat(\"Bayes' Theorem takes into account your initial belief about the event\n(like the usual chance of rain for the day) before new information is considered. \nEven though the weatherman correctly predicts rain 90% of the time..\nThe base probability of rain is already low, 5/365 = 1.36%.\nEven if the weatherman predicts rain,\nthe new information isn't strong enough to significantly update the probability\nhigh enough to consider it a \\\"high chance\\\" of rain.\nThe \\\"likelihood ratio\\\" is not large enough\nto drastically change the initial low probability of rain.\")\n\nBayes' Theorem takes into account your initial belief about the event\n(like the usual chance of rain for the day) before new information is considered. \nEven though the weatherman correctly predicts rain 90% of the time..\nThe base probability of rain is already low, 5/365 = 1.36%.\nEven if the weatherman predicts rain,\nthe new information isn't strong enough to significantly update the probability\nhigh enough to consider it a \"high chance\" of rain.\nThe \"likelihood ratio\" is not large enough\nto drastically change the initial low probability of rain.\n\n# Question C.\n# Last assignment from our textbook, pp. 55 Exercise # 2.3.\n# For a disease known to have a postoperative complication frequency of 20%,\n# a surgeon suggests a new procedure. She/he tests it on 10 patients and found\n# there are not complications.\n\n# C1.You will answer this question with the following code.\n# What is the probability of operating on 10 patients successfully\n# with the traditional method?\npaste(\"The probability is:\",dbinom(x=0,size=10,prob=.20),\"%\")\n\n[1] \"The probability is: 0.1073741824 %\""
  },
  {
    "objectID": "posts/Module 6 Assignment/index.html",
    "href": "posts/Module 6 Assignment/index.html",
    "title": "Module 6 Assignment",
    "section": "",
    "text": "Random Variables & Probability Distributions!\n\n# LIS4273 - Module 6. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n\n# Question A.\n\n# Consider a population consisting of the following values,\n# which represents the number of ice cream purchases during\n# one year for each of the five housemates.\n\n# 8, 14, 16, 10, 11.\nnumPurchases&lt;-c(8,14,16,10,11)\n# A1. Compute the mean of this population.\npopMean&lt;-mean(numPurchases)\npopMean\n\n[1] 11.8\n\n# A2. Select a random sample of size 2 out of the five members.\nrSample&lt;-sample(numPurchases,2)\nrSample\n\n[1] 16  8\n\n# A3. Compute the mean and standard deviation of your sample.\n\n# The Mean of the sample:\nrSampleMean&lt;-mean(rSample)\nrSampleMean\n\n[1] 12\n\n# The standard deviation of the sample:\nrSampleStdDev&lt;-sd(rSample)\nrSampleStdDev\n\n[1] 5.656854\n\n# A4. Compare the Mean and Standard deviation of your sample\n# to the entire population of this set (8,14, 16, 10, 11).\n\n# The standard deviation of the population:\npopStdDev&lt;-sd(numPurchases)\npopStdDev\n\n[1] 3.193744\n\ndf&lt;-data.frame(\"Population\"=c(popMean,popStdDev),\n               \"Sample\"=c(rSampleMean,rSampleStdDev),\n               row.names=(c(\"Mean\",\"Std Dev\")))\n# The data frame to compare the Mean and Standard deviation of the sample\n# to the entire population of this set (8,14, 16, 10, 11).\ndf\n\n        Population    Sample\nMean     11.800000 12.000000\nStd Dev   3.193744  5.656854\n\n# Question B. \n\n# Suppose that the sample size n = 100 and\n# the population proportion p = 0.95.\n\n# B1. Does the sample proportion p have approximately\n# a normal distribution? Explain.\ncat(\"The distribution is considered normal if both :\n      n*p &gt;= 5, and\n      n*q &gt;= 5.\n      n = 100\n      p = 0.95 and \n      q = 0.05.\n      \n      Therefore,\n      n*p = 100*0.95 = 95 &gt;= 5 and\n      n*q = 100*0.05 = 5 &gt;= 5.\n      \n      The sample proportion 'p' will have approximately\n      a normal distribution with these values.\")\n\nThe distribution is considered normal if both :\n      n*p &gt;= 5, and\n      n*q &gt;= 5.\n      n = 100\n      p = 0.95 and \n      q = 0.05.\n      \n      Therefore,\n      n*p = 100*0.95 = 95 &gt;= 5 and\n      n*q = 100*0.05 = 5 &gt;= 5.\n      \n      The sample proportion 'p' will have approximately\n      a normal distribution with these values.\n\n# B2. What is the smallest value of n for which the\n# sampling distribution of p is approximately normal?\ncat(\"The smallest value of 'n' for which the sampling distribution\n      of 'p' is approximately normal is 100.\n      \n      Any value less than 100, when multiplied with p = 0.95\n      and q = 0.05 will make n*q &lt;= 5,\n      and both n*p and n*q need to be &gt;= 5\n      in order to assume a normal distribution.\")\n\nThe smallest value of 'n' for which the sampling distribution\n      of 'p' is approximately normal is 100.\n      \n      Any value less than 100, when multiplied with p = 0.95\n      and q = 0.05 will make n*q &lt;= 5,\n      and both n*p and n*q need to be &gt;= 5\n      in order to assume a normal distribution.\n\n# Question C.\n# From our textbook, Chapter 2 Probability Exercises # 2.4.\n# Simulated coin tossing is probability better done using\n# function called 'rbinom()' than using the function called 'sample()'.\n\n# C1. Please explain the reason why 'rbinom()' is better\n# than 'sample()' in the coin tossing simulation.\ncat(\"The reason why the 'rbinom()' function is better\n      than the 'sample()' function in the coin tossing\n      simulation is that the 'sample()' function would need to\n      create a vector with 'Char' type elements like \\\"H\\\"\n      & \\\"T\\\", then set 'replace=TRUE', & set'prob=c(0.5,0.5)'.\n      That would require extra programming instructions\n      in order to simulate random sampling from that vector.\n      This could affect the outcomes / experiment results. \n      This extra step can be avoided by using 'rbinom()'\n      because it is designed to extract random sample outcomes from\n      the binomial distribution. This makes 'rbinom()' the better\n      choice because it is more efficient and readable as the code \n      clearly indicates that a binomial event, like a coin toss, is \n      being simulated.\"\n      )\n\nThe reason why the 'rbinom()' function is better\n      than the 'sample()' function in the coin tossing\n      simulation is that the 'sample()' function would need to\n      create a vector with 'Char' type elements like \"H\"\n      & \"T\", then set 'replace=TRUE', & set'prob=c(0.5,0.5)'.\n      That would require extra programming instructions\n      in order to simulate random sampling from that vector.\n      This could affect the outcomes / experiment results. \n      This extra step can be avoided by using 'rbinom()'\n      because it is designed to extract random sample outcomes from\n      the binomial distribution. This makes 'rbinom()' the better\n      choice because it is more efficient and readable as the code \n      clearly indicates that a binomial event, like a coin toss, is \n      being simulated."
  },
  {
    "objectID": "posts/Module 8 Assignment/index.html",
    "href": "posts/Module 8 Assignment/index.html",
    "title": "Module 8 Assignment",
    "section": "",
    "text": "An Exercise in ANOVA, analysis of variance!\n\n# LIS4273 - Module 8. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n\n# Question A.\n\n# A researcher is interested in the effects of drug against\n# stress reactions. She gives a reaction time test to three\n# different groups of subjects:\n# one group that is under a great deal of stress,\n# one group under a moderate amount of stress,\n# and a third group that is under almost no stress.\n# The subjects of the study were instructed to take the drug test\n# during their next stress episode and to report their stress on a\n# scale of 1 to 10 (10 being the most pain).\n\ndf&lt;-data.frame(\"High.Stress\"=c(10,9,8,9,10,8),\n               \"Moderate.Stress\"=c(8,10,6,7,8,8),\n               \"Low.Stress\"=c(4,6,6,4,2,2))\ndf\n\n  High.Stress Moderate.Stress Low.Stress\n1          10               8          4\n2           9              10          6\n3           8               6          6\n4           9               7          4\n5          10               8          2\n6           8               8          2\n\nstress.pain.level&lt;-c(df$High.Stress,df$Moderate.Stress,df$Low.Stress)\n\nsubject.group.amount&lt;-factor(c(rep(\"High\",6),\n                        rep(\"Moderate\",6),\n                        rep(\"Low\",6)),\n                        levels = c(\"High\",\"Moderate\",\"Low\"))\n\n# Report on drug and stress level by using R.\n# Provide a full summary report on the result\n# of ANOVA testing and what it means.\n\n# Look at the means for stress level by group:\ntapply(stress.pain.level,subject.group.amount,mean)\n\n    High Moderate      Low \n9.000000 7.833333 4.000000 \n\n# Look at the variations for stress level by group:\ntapply(stress.pain.level,subject.group.amount,var)\n\n    High Moderate      Low \n0.800000 1.766667 3.200000 \n\n# Look at a boxplot graph:\nboxplot(stress.pain.level ~ subject.group.amount,\n        main = \"Effects of Drug Against Stress Reactions\",\n        xlab = \"Stress amount groups\",\n        ylab = \"Stress level pain (1-10)\")\n\n\n\n\n\n\n\n# More specifically, report the following:\n# Df, Sum, Sq Mean, Sq, F value, Pr(&gt;F)\n\n# Did the drug have any affect on specific groups stress levels?\n\n# Test the difference between the means of the groups with ANOVA.\n\n# Null Ho: The mean stress levels are similar between groups\n# Alt  Ha: The mean stress levels are significantly different between groups\naov.out&lt;-aov(stress.pain.level ~ subject.group.amount,data = df)\nsummary(aov.out)\n\n                     Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nsubject.group.amount  2  82.11   41.06   21.36 4.08e-05 ***\nResiduals            15  28.83    1.92                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# The Df for subject.group.amount is '2' because there are three\n# groups sampled, so k-1 = 2, where k = number of groups sampled.\n# for the residuals row, the Df is '15' because there are 6 observations\n# in 3 samples, so N-k = 18-3 = 15.\n\n# Sum Sq is for 'Sum of the Squares' which is measuring the variance,\n# the higher this number is = more variance in the data, or groups.\n# Sum Sq for subject.group.amount, SS(B) = 82.11, indicating a large\n# variance between the groups, and Sum Sq for the residuals, SS(W) = 28.83\n# indicating a large variance within the groups as well.\n# Adding both of these would give the Total Variance.\n# SS(B)+SS(W)=SS(T)\n\n# Mean Sq normalizes the Sums of Squares by calculating mean squares.\n# Size of obtained mean differences (including treatment effects) = MS(B)\n# The Mean Sq for 'subject.group.amount' is: MS(B)=SS(B)/(K-1) = 41.06,\n# There is a large difference between the means in the sample groups.\n# Size of expected differences by chance (without treatment effects) = MS(W)\n# The Mean Sq for the residuals is: MS(W)=SS(W)/(N-k) = 1.92\n# The residuals row shows a smaller difference within the sample groups.\n\n# The F value is the result of MS(B)/MS(W) = 21.36\n# This test accounts for the random variation causing difference\n# in the mean squares and is the analysis of variance between means.\n# A value close to '1' indicates that the treatment has little to no effect\n# on the group means, which does not signify a difference between groups,\n# and there is not enough evidence to reject the Null Hypothesis that the\n# means are very similar or identical.\n# A large F value indicates a significant treatment effect, and would \n# cause the Null Hypothesis of similar means to be rejected because there\n# is enough evidence for the Alternative Hypothesis to be considered.\n\n# The Pr(&gt;F) from ANOVA works like similar p-value significance tests.\n# 95% confidence needs a p-value less than 0.05 to reject the Null.\n# In this test the p-value = 4.08e-05, is significantly smaller than 0.001,\n# indicating that the statistics are very significant.\n\n# The large F value at 21.36 and the low 4.08e-05 p-value suggests\n# evidence against the null hypothesis. Therefore, it can be assumed\n# that the mean stress levels differ significantly among the three groups.\n\n# Question B.\n\n# From our Textbook: Introductory Statistics with R.\n# Chapter # 6 Exercises 6.1 pp. 127 plus.\n# The zelazo data (taken from the textbook's R package called ISwR)\n# are in the form of a list of vectors, one for each of the four groups.\n\n# B1. Convert the data to a form suitable for the user of lm,\n# and calculate the relevant test.\nlibrary(ISwR)\ndata(\"zelazo\")\nsummary(zelazo)\n\n        Length Class  Mode   \nactive  6      -none- numeric\npassive 6      -none- numeric\nnone    6      -none- numeric\nctr.8w  5      -none- numeric\n\n# To convert the data for linear model, lm()\n# A 'value' column will hold the combined response variables\n# A 'group' factor will create the categorical variable that\n# will be used to combine the predictor variables\nzelazo.df&lt;-data.frame(\nvalue=unlist(zelazo,use.names = F),\ngroup=factor(rep(c(\"active\",\"passive\",\"none\",\"ctr.8w\"),sapply(zelazo,length)),\nlevels = c(\"active\",\"passive\",\"none\",\"ctr.8w\")))\nzelazo.df\n\n   value   group\n1   9.00  active\n2   9.50  active\n3   9.75  active\n4  10.00  active\n5  13.00  active\n6   9.50  active\n7  11.00 passive\n8  10.00 passive\n9  10.00 passive\n10 11.75 passive\n11 10.50 passive\n12 15.00 passive\n13 11.50    none\n14 12.00    none\n15  9.00    none\n16 11.50    none\n17 13.25    none\n18 13.00    none\n19 13.25  ctr.8w\n20 11.50  ctr.8w\n21 12.00  ctr.8w\n22 13.50  ctr.8w\n23 11.50  ctr.8w\n\n# Boxplot to view age at walking values by four group levels\nboxplot(zelazo.df$value~zelazo.df$group,\n        main = \"Effects of Training on Infant Walking Ages\",\n        xlab = \"Training Level Groups\",\n        ylab = \"Walking Age in Months\")\n\n\n\n\n\n\n\n# Model and call the linear model, lm()\n# This will model the relationship between the magnitude of one\n# variable and that of a second\nzelazo.lm&lt;-lm(zelazo.df$value~zelazo.df$group)\nsummary(zelazo.lm)\n\n\nCall:\nlm(formula = zelazo.df$value ~ zelazo.df$group)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7083 -0.8500 -0.3500  0.6375  3.6250 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             10.1250     0.6191  16.355 1.19e-12 ***\nzelazo.df$grouppassive   1.2500     0.8755   1.428   0.1696    \nzelazo.df$groupnone      1.5833     0.8755   1.809   0.0864 .  \nzelazo.df$groupctr.8w    2.2250     0.9182   2.423   0.0255 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.516 on 19 degrees of freedom\nMultiple R-squared:  0.2528,    Adjusted R-squared:  0.1348 \nF-statistic: 2.142 on 3 and 19 DF,  p-value: 0.1285\n\n# The residual standard error of 1.516 could be considered small\n# indicating that the regression model fits the data set well.\n# The median value in the distribution of the residuals is close to zero\n# at -0.3500 and the min & max are roughly equal in absolute value.\n# An F-value of 2.14 with a p-value of 0.1285 indicates that there is not\n# enough evidence to reject the null hypothesis that the model with no\n# independent variables fits the data as well as the model including treatment\n# effects.The observed differences between groups are likely due to chance,\n# as the p-value is relatively high and not statistically significant at the\n# standard 0.05 significance level. To find the relationship between groups\n# that is causing the difference, further investigation is necessary.\n\n# Consider t-tests comparing selected subgroups\n# or obtained by combining groups.\n\n# The only group in the regression summary that showed significant\n# statistical results was the 'ctr.8w' control group with a t-value\n# of 2.423 and a Pr(&gt;|t|) value of 0.0255 * indicating significant evidence\n# to reject the null that the true coefficient of the control group and the\n# intercept is equal to zero, and a relationship between the variables exists.\n\n# So I will begin by using t-tests to compare the subgroups of the \n# control group and the other groups to test for significant differences\n# between the means of the groups.\ntapply(zelazo.df$value,zelazo.df$group,var)\n\n  active  passive     none   ctr.8w \n2.093750 3.593750 2.310417 0.925000 \n\n# The variances are not the same between the groups so the Welch's\n# variant of the t-test is sufficient.\n\n# Two sample t-test comparing the means of 'none' group to 'control' group\nt.test.result1&lt;-t.test(zelazo.df$value~zelazo.df$group,\ndata=zelazo.df,\nsubset=group%in%c(\"none\",\"ctr.8w\"))\nt.test.result1\n\n\n    Welch Two Sample t-test\n\ndata:  zelazo.df$value by zelazo.df$group\nt = -0.84986, df = 8.5046, p-value = 0.4187\nalternative hypothesis: true difference in means between group none and group ctr.8w is not equal to 0\n95 percent confidence interval:\n -2.364947  1.081614\nsample estimates:\n  mean in group none mean in group ctr.8w \n            11.70833             12.35000 \n\n# The p-value of 0.4187 is &gt; 0.05 alpha, so there is not significant evidence\n# to reject the null hypothesis that there is no difference between the means\n\n# Two sample t-test comparing the means of 'passive' group to 'control' group\nt.test.result2&lt;-t.test(zelazo.df$value~zelazo.df$group,\ndata=zelazo.df,\nsubset=group%in%c(\"passive\",\"ctr.8w\"))\nt.test.result2\n\n\n    Welch Two Sample t-test\n\ndata:  zelazo.df$value by zelazo.df$group\nt = -1.1012, df = 7.6531, p-value = 0.3042\nalternative hypothesis: true difference in means between group passive and group ctr.8w is not equal to 0\n95 percent confidence interval:\n -3.032993  1.082993\nsample estimates:\nmean in group passive  mean in group ctr.8w \n               11.375                12.350 \n\n# The p-value of 0.3042 is &gt; 0.05 alpha, so there is not significant evidence\n# to reject the null hypothesis that there is no difference between the means\n\n# Two sample t-test comparing the means of active group to control group\nt.test.result3&lt;-t.test(zelazo.df$value~zelazo.df$group,\ndata=zelazo.df,\nsubset=group%in%c(\"active\",\"ctr.8w\"))\nt.test.result3\n\n\n    Welch Two Sample t-test\n\ndata:  zelazo.df$value by zelazo.df$group\nt = -3.0449, df = 8.6632, p-value = 0.01453\nalternative hypothesis: true difference in means between group active and group ctr.8w is not equal to 0\n95 percent confidence interval:\n -3.8878619 -0.5621381\nsample estimates:\nmean in group active mean in group ctr.8w \n              10.125               12.350 \n\n# The p-value of 0.01453 is &lt; 0.05 alpha, so there is significant evidence\n# to reject the null hypothesis that there is no difference between the means!\n# We can conclude that a difference between these two groups' means exists!\n\n\n\n# B2. Consider the ANOVA test (one-way or two-way) for this dataset (zelazo)\n\n# The one-way ANOVA test will test the null hypothesis that there is no\n# difference between the means of the group that received the treatment and \n# the means of the groups that did not receive the treatment.\n\n# h0: All group means are equal\n# ha: All group means are not equal\n\n# The one-way test to compare differences between the group means\noneway.test(zelazo.df$value~zelazo.df$group)\n\n\n    One-way analysis of means (not assuming equal variances)\n\ndata:  zelazo.df$value and zelazo.df$group\nF = 2.7759, num df = 3.000, denom df = 10.506, p-value = 0.09373\n\n# With an F value = 2.7759, and p-value = 0.09373, we fail to reject the null\n# hypothesis that all group means are equal. This is strange because we know\n# they are different somehow, further analysis of the groups is needed.\n\n# The aov() function fits analysis of variance (ANOVA)\n# models directly to the data\nzelazo.aov&lt;-aov(zelazo.df$value~zelazo.df$group,data=zelazo.df)\nzelazo.aov\n\nCall:\n   aov(formula = zelazo.df$value ~ zelazo.df$group, data = zelazo.df)\n\nTerms:\n                zelazo.df$group Residuals\nSum of Squares         14.77781  43.68958\nDeg. of Freedom               3        19\n\nResidual standard error: 1.516394\nEstimated effects may be unbalanced\n\nsummary(zelazo.aov)\n\n                Df Sum Sq Mean Sq F value Pr(&gt;F)\nzelazo.df$group  3  14.78   4.926   2.142  0.129\nResiduals       19  43.69   2.299               \n\n# It returns an ANOVA table with sources of variation and associated statistics\n\n# The anova() function performs analysis of variance (ANOVA)\n# on model objects\nanova(zelazo.lm)\n\nAnalysis of Variance Table\n\nResponse: zelazo.df$value\n                Df Sum Sq Mean Sq F value Pr(&gt;F)\nzelazo.df$group  3 14.778  4.9259  2.1422 0.1285\nResiduals       19 43.690  2.2995               \n\n# It returns an ANOVA table comparing models or factors,\n# showing sources of variation and statistics\n\n# Which yields the same results as the lm() \nsummary(zelazo.lm)\n\n\nCall:\nlm(formula = zelazo.df$value ~ zelazo.df$group)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7083 -0.8500 -0.3500  0.6375  3.6250 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             10.1250     0.6191  16.355 1.19e-12 ***\nzelazo.df$grouppassive   1.2500     0.8755   1.428   0.1696    \nzelazo.df$groupnone      1.5833     0.8755   1.809   0.0864 .  \nzelazo.df$groupctr.8w    2.2250     0.9182   2.423   0.0255 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.516 on 19 degrees of freedom\nMultiple R-squared:  0.2528,    Adjusted R-squared:  0.1348 \nF-statistic: 2.142 on 3 and 19 DF,  p-value: 0.1285\n\nplot(zelazo.lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Because the p-value is &gt; 0.05, we fail to reject the null hypothesis\n# that each group mean is equal, However, Post-Hoc Tests can be\n# used to explore how the groups differ from each other to learn more\n# about where the variance in the means exists.\n\n# The Tukey Test offers a glimpse at the relationships between all of the\n# pairs and combinations of the groups\nTukeyHSD(zelazo.aov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = zelazo.df$value ~ zelazo.df$group, data = zelazo.df)\n\n$`zelazo.df$group`\n                    diff        lwr      upr     p adj\npassive-active 1.2500000 -1.2117450 3.711745 0.4982812\nnone-active    1.5833333 -0.8784116 4.045078 0.3000594\nctr.8w-active  2.2250000 -0.3568999 4.806900 0.1063883\nnone-passive   0.3333333 -2.1284116 2.795078 0.9806495\nctr.8w-passive 0.9750000 -1.6068999 3.556900 0.7160591\nctr.8w-none    0.6416667 -1.9402332 3.223567 0.8962600\n\n# The adjusted p-value will indicate if there is a significant\n# statistical relationship between two groups.\n\n# The ctr.8w-active is closest to being less than 0.05 at 0.1063883,\n# but is still not considered significant enough to be outside of the 95%\n# confidence level"
  }
]