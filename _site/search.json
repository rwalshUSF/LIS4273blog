[
  {
    "objectID": "posts/Welcome/index.html",
    "href": "posts/Welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in my LIS4273 blog. Welcome!"
  },
  {
    "objectID": "posts/Module 6 Assignment/index.html",
    "href": "posts/Module 6 Assignment/index.html",
    "title": "Module 6 Assignment",
    "section": "",
    "text": "Random Variables & Probability Distributions!\n\n# LIS4273 - Module 6. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n\n# Question A.\n\n# Consider a population consisting of the following values,\n# which represents the number of ice cream purchases during\n# one year for each of the five housemates.\n\n# 8, 14, 16, 10, 11.\nnumPurchases&lt;-c(8,14,16,10,11)\n# A1. Compute the mean of this population.\npopMean&lt;-mean(numPurchases)\npopMean\n\n[1] 11.8\n\n# A2. Select a random sample of size 2 out of the five members.\nrSample&lt;-sample(numPurchases,2)\nrSample\n\n[1] 16  8\n\n# A3. Compute the mean and standard deviation of your sample.\n\n# The Mean of the sample:\nrSampleMean&lt;-mean(rSample)\nrSampleMean\n\n[1] 12\n\n# The standard deviation of the sample:\nrSampleStdDev&lt;-sd(rSample)\nrSampleStdDev\n\n[1] 5.656854\n\n# A4. Compare the Mean and Standard deviation of your sample\n# to the entire population of this set (8,14, 16, 10, 11).\n\n# The standard deviation of the population:\npopStdDev&lt;-sd(numPurchases)\npopStdDev\n\n[1] 3.193744\n\ndf&lt;-data.frame(\"Population\"=c(popMean,popStdDev),\n               \"Sample\"=c(rSampleMean,rSampleStdDev),\n               row.names=(c(\"Mean\",\"Std Dev\")))\n# The data frame to compare the Mean and Standard deviation of the sample\n# to the entire population of this set (8,14, 16, 10, 11).\ndf\n\n        Population    Sample\nMean     11.800000 12.000000\nStd Dev   3.193744  5.656854\n\n# Question B. \n\n# Suppose that the sample size n = 100 and\n# the population proportion p = 0.95.\n\n# B1. Does the sample proportion p have approximately\n# a normal distribution? Explain.\ncat(\"The distribution is considered normal if both :\n      n*p &gt;= 5, and\n      n*q &gt;= 5.\n      n = 100\n      p = 0.95 and \n      q = 0.05.\n      \n      Therefore,\n      n*p = 100*0.95 = 95 &gt;= 5 and\n      n*q = 100*0.05 = 5 &gt;= 5.\n      \n      The sample proportion 'p' will have approximately\n      a normal distribution with these values.\")\n\nThe distribution is considered normal if both :\n      n*p &gt;= 5, and\n      n*q &gt;= 5.\n      n = 100\n      p = 0.95 and \n      q = 0.05.\n      \n      Therefore,\n      n*p = 100*0.95 = 95 &gt;= 5 and\n      n*q = 100*0.05 = 5 &gt;= 5.\n      \n      The sample proportion 'p' will have approximately\n      a normal distribution with these values.\n\n# B2. What is the smallest value of n for which the\n# sampling distribution of p is approximately normal?\ncat(\"The smallest value of 'n' for which the sampling distribution\n      of 'p' is approximately normal is 100.\n      \n      Any value less than 100, when multiplied with p = 0.95\n      and q = 0.05 will make n*q &lt;= 5,\n      and both n*p and n*q need to be &gt;= 5\n      in order to assume a normal distribution.\")\n\nThe smallest value of 'n' for which the sampling distribution\n      of 'p' is approximately normal is 100.\n      \n      Any value less than 100, when multiplied with p = 0.95\n      and q = 0.05 will make n*q &lt;= 5,\n      and both n*p and n*q need to be &gt;= 5\n      in order to assume a normal distribution.\n\n# Question C.\n# From our textbook, Chapter 2 Probability Exercises # 2.4.\n# Simulated coin tossing is probability better done using\n# function called 'rbinom()' than using the function called 'sample()'.\n\n# C1. Please explain the reason why 'rbinom()' is better\n# than 'sample()' in the coin tossing simulation.\ncat(\"The reason why the 'rbinom()' function is better\n      than the 'sample()' function in the coin tossing\n      simulation is that the 'sample()' function would need to\n      create a vector with 'Char' type elements like \\\"H\\\"\n      & \\\"T\\\", then set 'replace=TRUE', & set'prob=c(0.5,0.5)'.\n      That would require extra programming instructions\n      in order to simulate random sampling from that vector.\n      This could affect the outcomes / experiment results. \n      This extra step can be avoided by using 'rbinom()'\n      because it is designed to extract random sample outcomes from\n      the binomial distribution. This makes 'rbinom()' the better\n      choice because it is more efficient and readable as the code \n      clearly indicates that a binomial event, like a coin toss, is \n      being simulated.\"\n      )\n\nThe reason why the 'rbinom()' function is better\n      than the 'sample()' function in the coin tossing\n      simulation is that the 'sample()' function would need to\n      create a vector with 'Char' type elements like \"H\"\n      & \"T\", then set 'replace=TRUE', & set'prob=c(0.5,0.5)'.\n      That would require extra programming instructions\n      in order to simulate random sampling from that vector.\n      This could affect the outcomes / experiment results. \n      This extra step can be avoided by using 'rbinom()'\n      because it is designed to extract random sample outcomes from\n      the binomial distribution. This makes 'rbinom()' the better\n      choice because it is more efficient and readable as the code \n      clearly indicates that a binomial event, like a coin toss, is \n      being simulated."
  },
  {
    "objectID": "posts/Module 4 Assignment/index.html",
    "href": "posts/Module 4 Assignment/index.html",
    "title": "Module 4 Assignment",
    "section": "",
    "text": "An exercise in probability!\n\n# LIS4273 - Module 4. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n#\ntable1&lt;-data.frame(\"B\"=c(10,20,30),\"B1\"=c(20,40,60),\"Totals\"=c(30,60,90),\nrow.names = c(\"A\",\"A1\",\"Totals\"))\nlibrary(gridExtra)\ngrid.table(table1)\n\n\n\n\n\n\n\n#Question A.\n#Based on Table 1, what is the probability of:\n#A1. Event A ?\nA&lt;-30/90\npaste(\"The probability of event A = \",format(round(A,4)),\"%\")\n\n[1] \"The probability of event A =  0.3333 %\"\n\n#A2. Event B ?\nB&lt;-30/90\npaste(\"The probability of event B = \",format(round(B,4)),\"%\")\n\n[1] \"The probability of event B =  0.3333 %\"\n\n#A3. Event A or B ?\nAorB&lt;-((30/90)+(30/90))-(10/90)\npaste(\"The probability of event A or B = \",format(round(AorB,4)),\"%\")\n\n[1] \"The probability of event A or B =  0.5556 %\"\n\n#A4. P(A or B) = P(A) + P(B)\nAorB == A + B\n\n[1] FALSE\n\n# Question B.\n# In terms of probabilities, we know the following:\n# P( A1 ) = 5/365 =0.0136985 [It rains 5 days out of the year.]\n# P( A2 ) = 360/365 = 0.9863014 [It does not rain 360 days out of the year.]\n# P( B | A1 ) = 0.9 [When it rains, the weatherman predicts rain 90% of the time.]\n# P( B | A2 ) = 0.1 [When it does not rain, the weatherman predicts rain 10% of the time.]\n# We want to know P( A1 | B ), the probability it will rain on the day of Jane's wedding,\n# given a forecast for rain by the weatherman. \n\n# The answer can be determined from Bayes' theorem, as shown below.\n\n# P( A1 | B ) = P( A1 ) P( B | A1 ) / P( A1 ) P( B | A1 ) + P( A2 ) P( B | A2 )\n# P( A1 | B ) = (0.014)(0.9) / [ (0.014)(0.9) + (0.986)(0.1) ]\n# P( A1 | B ) = 0.111\n# Note the somewhat unintuitive result. Even when the weatherman predicts rain,\n# it only rains only about 11% of the time. \n# Despite the weatherman's gloomy prediction, there is a good chance that Jane\n# will not get rained on at her wedding.\n\n# Please answer the following questions:\n# B1. Is this answer True or False ?\nprint(\"TRUE\")\n\n[1] \"TRUE\"\n\n# B2. Please explain why:\ncat(\"Bayes' Theorem takes into account your initial belief about the event\n(like the usual chance of rain for the day) before new information is considered. \nEven though the weatherman correctly predicts rain 90% of the time..\nThe base probability of rain is already low, 5/365 = 1.36%.\nEven if the weatherman predicts rain,\nthe new information isn't strong enough to significantly update the probability\nhigh enough to consider it a \\\"high chance\\\" of rain.\nThe \\\"likelihood ratio\\\" is not large enough\nto drastically change the initial low probability of rain.\")\n\nBayes' Theorem takes into account your initial belief about the event\n(like the usual chance of rain for the day) before new information is considered. \nEven though the weatherman correctly predicts rain 90% of the time..\nThe base probability of rain is already low, 5/365 = 1.36%.\nEven if the weatherman predicts rain,\nthe new information isn't strong enough to significantly update the probability\nhigh enough to consider it a \"high chance\" of rain.\nThe \"likelihood ratio\" is not large enough\nto drastically change the initial low probability of rain.\n\n# Question C.\n# Last assignment from our textbook, pp. 55 Exercise # 2.3.\n# For a disease known to have a postoperative complication frequency of 20%,\n# a surgeon suggests a new procedure. She/he tests it on 10 patients and found\n# there are not complications.\n\n# C1.You will answer this question with the following code.\n# What is the probability of operating on 10 patients successfully\n# with the traditional method?\npaste(\"The probability is:\",dbinom(x=0,size=10,prob=.20),\"%\")\n\n[1] \"The probability is: 0.1073741824 %\""
  },
  {
    "objectID": "posts/Module 2 Assignment/index.html",
    "href": "posts/Module 2 Assignment/index.html",
    "title": "Module 2 Assignment",
    "section": "",
    "text": "This Function Calculates The Mean!\nHere is how it works!\n\n# LIS4273 - Module 2. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n\n# Create a vector using the c() function\n# and store the results in the 'assignment2' variable/object\n\nassignment2 &lt;- c(6,18,14,22,27,17,22,20,22)\n\n# Create a function named 'myMean' that will\n# accept 'assignment2' as an input variable/argument and then\n# calculate & return the value of the sum of all values in the\n# 'assignment2' vector using the sum() function, and then divide\n# that result by the number of components in the 'assignment2'\n# vector using the length() function. the result is stored in the\n# 'result' variable/object.\n\nmyMean &lt;- function(assignment2) \n{\n  return(sum(assignment2)/length(assignment2))\n}\n\n# print the result as output by calling 'myMean' with \n# 'assignment2' as the argument\n\nresult &lt;- myMean(assignment2)\nresult\n\n[1] 18.66667\n\n# Here is the output!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Robert Walsh",
    "section": "",
    "text": "UNIVERSITY OF SOUTH FLORIDA - SCHOOL OF INFORMATION - LIS4273\nA blog for sharing my class assignments."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": " USF - LIS4273 Advanced Stats - Blog ",
    "section": "",
    "text": "Module 7 Assignment\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\n\n\n\n\n\n\nModule 6 Assignment\n\n\n\n\n\n\n\n\n\n\n\nFeb 17, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\n\n\n\n\n\n\nModule 5 Assignment\n\n\n\n\n\n\n\n\n\n\n\nFeb 11, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\n\n\n\n\n\n\nModule 4 Assignment\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\n\n\n\n\n\n\nModule 3 Assignment\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\n\n\n\n\n\n\nModule 2 Assignment\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2025\n\n\nRobert Walsh\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Module 3 Assignment/index.html",
    "href": "posts/Module 3 Assignment/index.html",
    "title": "Module 3 Assignment",
    "section": "",
    "text": "An exercise in descriptive statistics!\nThis was a lot of fun!\n\n# LIS4273 - Module 3. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n#\nlibrary(DescTools)\n# Import the two data sets from .csv file\ndataSets&lt;-read.csv(\"C:/LIS4273blog/Mod3DataSets.csv\",header = TRUE,sep = \",\")\ndataSets\n\n  Set.1 Set.2\n1    10    20\n2     2    12\n3     3    13\n4     2    12\n5     4    14\n6     2    12\n7     5    15\n\n# (A1) For each set, compute the mean, median, \n# and mode under Central Tendency\n#\n# ----------------\n# CENTRAL TENDENCY\n# ----------------\n# Set # 1, Mean:\nmean(dataSets$Set.1)\n\n[1] 4\n\n# Set # 1, Median:\nmedian(dataSets$Set.1)\n\n[1] 3\n\n# Set # 1, Mode:\nMode(dataSets$Set.1)\n\n[1] 2\nattr(,\"freq\")\n[1] 3\n\n# ----------------\n# CENTRAL TENDENCY\n# ----------------\n# Set # 2 Mean:\nmean(dataSets$Set.2)\n\n[1] 14\n\n# Set # 2 Median:\nmedian(dataSets$Set.2)\n\n[1] 13\n\n# Set # 2 Mode:\nMode(dataSets$Set.2)\n\n[1] 12\nattr(,\"freq\")\n[1] 3\n\n# (A2) For each set, compute the range, interquartile, \n# variance, and standard deviation under Variation\n#\n# ---------\n# VARIATION\n# ---------\nset1_minMax&lt;-range(dataSets$Set.1)\n# The Min & Max of Set # 1 are:\nset1_minMax\n\n[1]  2 10\n\nset1_range&lt;-set1_minMax[2]-set1_minMax[1]\n# The Range of Set # 1 is:\nset1_range\n\n[1] 8\n\nquartileSet1&lt;-quantile(dataSets$Set.1)\n# The Quartiles of Set # 1 are:\nquartileSet1\n\n  0%  25%  50%  75% 100% \n 2.0  2.0  3.0  4.5 10.0 \n\ninterQuartileRangeSet1&lt;-as.numeric(quartileSet1[4])-as.numeric(quartileSet1[2])\n# The InterQuartile Range for Set # 1 is:\ninterQuartileRangeSet1\n\n[1] 2.5\n\n# The Variance of Set # 1 is:\nvar(dataSets$Set.1)\n\n[1] 8.333333\n\n# The Standard Deviation of Set # 1 is:\nsd(dataSets$Set.1)\n\n[1] 2.886751\n\n# ---------\n# VARIATION\n# ---------\nset2_minMax&lt;-range(dataSets$Set.2)\n# The Min & Max of Set # 2 are:\nset2_minMax\n\n[1] 12 20\n\nset2_range&lt;-set2_minMax[2]-set2_minMax[1]\n# The Range of Set # 2 is:\nset1_range\n\n[1] 8\n\nquartileSet2&lt;-quantile(dataSets$Set.2)\n# The Quartiles of Set # 2 are:\nquartileSet2\n\n  0%  25%  50%  75% 100% \n12.0 12.0 13.0 14.5 20.0 \n\ninterQuartileRangeSet2&lt;-as.numeric(quartileSet2[4])-as.numeric(quartileSet2[2])\n# The InterQuartile Range for Set # 2 is:\ninterQuartileRangeSet2\n\n[1] 2.5\n\n# The Variance of Set # 2 is:\nvar(dataSets$Set.2)\n\n[1] 8.333333\n\n# The Standard Deviation of Set # 2 is:\nsd(dataSets$Set.2)\n\n[1] 2.886751\n\n# (A3) Compare your results between Set # 1 vs. Set # 2\n# by discussing the differences between the two sets.\n#\n# --------------------\n# SUMMARY / COMPARISON\n# --------------------\n#\ncv1&lt;-(sd(dataSets$Set.1)/mean(dataSets$Set.1))*100\ncv2&lt;-(sd(dataSets$Set.2)/mean(dataSets$Set.2))*100\ncompdf&lt;-data.frame(\"Mean\"=c(mean(dataSets$Set.1),mean(dataSets$Set.2)),\n\"Median\"=c(median(dataSets$Set.1),median(dataSets$Set.2)),\n\"Mode\"=c(Mode(dataSets$Set.1),Mode(dataSets$Set.2)),\n\"Range\"=c(set1_range,set2_range),\n\"Variance\"=c(var(dataSets$Set.1),var(dataSets$Set.2)),\n\"Std Dev\"=c(sd(dataSets$Set.1),sd(dataSets$Set.2)),\n\"CV\"=c(cv1,cv2),\nrow.names = c(\"Set.1\",\"Set.2\"))\ncompdf\n\n      Mean Median Mode Range Variance  Std.Dev       CV\nSet.1    4      3    2     8 8.333333 2.886751 72.16878\nSet.2   14     13   12     8 8.333333 2.886751 20.61965\n\nsummary(dataSets$Set.1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    2.0     2.0     3.0     4.0     4.5    10.0 \n\nsummary(dataSets$Set.2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   12.0    12.0    13.0    14.0    14.5    20.0 \n\n# ------------------------\n# COEFFICIENT OF VARIATION\n# ------------------------\n# Coefficient of variation, as percent:\n# Set # 1:\ncv1\n\n[1] 72.16878\n\n# Set # 2:\ncv2\n\n[1] 20.61965\n\n# Although both sets had an equal range and variance...\n# They had significantly different means.\n# The set of data that has the greatest spread of variance\n# relative to the mean is:\nif (cv1&gt;cv2) {paste(\"Set # 1, Coefficient of Variance = \", cv1, \"VS.\", cv2)\n} else {paste(\"Set # 2, Coefficient of Variance = \", cv2, \"VS.\", cv1)}\n\n[1] \"Set # 1, Coefficient of Variance =  72.1687836487032 VS. 20.6196524710581\""
  },
  {
    "objectID": "posts/Module 5 Assignment/index.html",
    "href": "posts/Module 5 Assignment/index.html",
    "title": "Module 5 Assignment",
    "section": "",
    "text": "An exercise in Hypothesis Testing & Correlation!\n\n# LIS4273 - Module 5. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n\n# Question A.\n\n# The director of manufacturing at a cookies company needs to determine\n# whether a new machine is able to produce a particular type of cookies\n# according to the manufacturer's specifications, which indicate that\n# cookies should have a mean of 70 and standard deviation of 3.5 pounds.\n# A sample of 49 cookies reveals a sample mean breaking strength\n# of 69.1 pounds.\n\n# A1. State the null and alternative hypothesis :\n\n# Null Hypothesis - Ho: The mean µ = 70\n# New machine is able to produce cookies within spec.\n# Mean breaking strength is equal to 70\n\n# Alt Hypothesis - Ha: The mean µ ≠ 70\n# New machine is not able to produce cookies within spec.\n# Mean breaking strength is not equal to 70\n\n# A2. Is there evidence that the machine is not meeting the manufacturer's\n# specifications for average strength?\n\n# Use a 0.05 level of significance.\nalpha &lt;- 0.05\n# Population Mean = 70\na &lt;- 70\n# Standard Deviation = 3.5\ns &lt;- 3.5\n# Sample Size = 49\nn &lt;- 49\n# Sample Mean = 69.1\nxbar &lt;- 69.1\n# Calculate Test Statistic:\nz &lt;- (xbar-a)/(s/sqrt(n))\nz\n\n[1] -1.8\n\n# Use qnorm() to determine critical values @ 0.05 alpha\n# Two tailed test would identify a 0.025 rejection area on each tail\nz.half.alpha &lt;- qnorm(1-alpha/2)\n# The critical vales are - 1.96 and + 1.96\nz.half.alpha\n\n[1] 1.959964\n\n-z.half.alpha\n\n[1] -1.959964\n\n# Determine if the Test Statistic is in the rejection region.\nz &lt; -z.half.alpha || abs(z) &gt; z.half.alpha\n\n[1] FALSE\n\n# -1.96 &gt; -1.80 &gt; 0 &lt; 1.80 &lt; 1.96\n# The Test Statistic falls between the critical values in the\n# 'do not reject Ho/Null' region. Therefore we can infer\n# that there is evidence that the machine is meeting the manufacturer’s \n# specifications for average strength.\n\n# A3. Compute the p value and interpret its meaning.\n\n# Use pnorm() to calculate the p value using the Test Statistic 'Z'\n# Then multiply the value by two for the two tailed test.\np &lt;- 2*pnorm(z)\n# We get a p value of:\np\n\n[1] 0.07186064\n\n# Test to see if this p value is greater than alpha.\np &gt; alpha\n\n[1] TRUE\n\n# Because the p value is greater than alpha, there is not enough\n# evidence to reject the Null hypothesis - Ho.\n\n# A4. What would be your answer in (A2) if the standard\n# deviation were specified as 1.75 pounds?\n\nalpha &lt;- 0.05\n# Population Mean = 70\na &lt;- 70\n# Standard Deviation = 1.75\ns &lt;- 1.75\n# Sample Size = 49\nn &lt;- 49\n# Sample Mean = 69.1\nxbar &lt;- 69.1\n# Calculate Test Statistic:\nz &lt;- (xbar-a)/(s/sqrt(n))\nz\n\n[1] -3.6\n\n# Use qnorm() to determine critical values @ 0.05 alpha\n# Two tailed test would identify a 0.025 rejection area on each tail\nz.half.alpha &lt;- qnorm(1-alpha/2)\n# The critical vales are - 1.96 and + 1.96\nz.half.alpha\n\n[1] 1.959964\n\n-z.half.alpha\n\n[1] -1.959964\n\n# Determine if the Test Statistic is in the rejection region.\nz &lt; -z.half.alpha || abs(z) &gt; z.half.alpha\n\n[1] TRUE\n\n# -3.60 &gt; -1.96 &gt; 0 &lt; 1.96 &lt; 3.60\n# The Test Statistic falls outside the critical values in the\n# 'reject Ho/Null' region. Therefore we can infer\n# that there is evidence that the machine is not meeting the \n# manufacturer’s specifications for average strength.\n\n# A5. What would be your answer in (A2) if the sample mean were \n# 69 pounds and the standard deviation is 3.5 pounds?\n\nalpha &lt;- 0.05\n# Population Mean = 70\na &lt;- 70\n# Standard Deviation = 3.5\ns &lt;- 3.5\n# Sample Size = 49\nn &lt;- 49\n# Sample Mean = 69\nxbar &lt;- 69\n# Calculate Test Statistic:\nz &lt;- (xbar-a)/(s/sqrt(n))\nz\n\n[1] -2\n\n# Use qnorm() to determine critical values @ 0.05 alpha\n# Two tailed test would identify a 0.025 rejection area on each tail\nz.half.alpha &lt;- qnorm(1-alpha/2)\n# The critical vales are - 1.96 and + 1.96\nz.half.alpha\n\n[1] 1.959964\n\n-z.half.alpha\n\n[1] -1.959964\n\n# Determine if the Test Statistic is in the rejection region.\nz &lt; -z.half.alpha || abs(z) &gt; z.half.alpha\n\n[1] TRUE\n\n# -2 &gt; -1.96 &gt; 0 &lt; 1.96 &lt; 2\n# The Test Statistic falls outside the critical values in the\n# 'reject Ho/Null' region. Therefore we can infer\n# that there is evidence that the machine is not meeting the \n# manufacturer’s specifications for average strength.\n\n\n# Question B. If x̅ = 85, σ = standard deviation = 8, and n=64,\n# set up 95% confidence interval estimate of the population mean μ.\n\n# The 'Zc' Critical Value for a 95% Level of Confidence C = 1.96\nzc &lt;- 1.96\n# Sample Mean = 85\nxbar &lt;- 85\n# Standard Deviation = 8\ns &lt;- 8\n# Sample Size = 64\nn &lt;- 64\n\n# Calculate Upper Confidence Limit value\nxBarPlusE &lt;- xbar + (zc*(s/sqrt(n)))\n# Calculate Upper Confidence Limit value\nxBarMinusE &lt;- xbar - (zc*(s/sqrt(n)))\n# Therefore the 95% confidence interval would be:\nprint(\"(83.04,86.96)\")\n\n[1] \"(83.04,86.96)\"\n\n# There is a 95% probability that the population mean\n# would be in between these two values.\n\n\n# Question C. Given the time spent on assignments each week\n# for the sampled girl group and boy group, respectively,\nlibrary(GGally)\n\nLoading required package: ggplot2\n\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\ngirls_grades &lt;- c(89, 90, 91, 95, 98, 99, 96, 99)\ngirls_time_spend &lt;- c(19, 20, 22, 25, 28, 30, 32, 36)\n\nboys_grades &lt;- c(86, 84, 92, 93, 93, 96, 98, 98)\nboys_time_spend &lt;- c(15, 19, 22, 23, 25, 29, 30, 40)\n\n# Please perform the correlation analysis:\n\n# C1. Calculate the correlation coefficient (Pearson) between\n# time spent and grade for girls' and boys' datasets, respectively.\n\n# The Pearson correlation coefficient between time spent and grade\n# for the Girls' dataset:\nx&lt;-c(girls_grades)\ny&lt;-c(girls_time_spend)\ngirlsData&lt;-data.frame(x,y)\nround(cor(girlsData,method=\"pearson\"),digits=2)\n\n     x    y\nx 1.00 0.91\ny 0.91 1.00\n\n# This result is close to 1 so a strong positive relation is implied.\n\n# The Pearson correlation coefficient between time spent and grade\n# for the Boys' dataset:\nx&lt;-c(boys_grades)\ny&lt;-c(boys_time_spend)\nboysData&lt;-data.frame(x,y)\nround(cor(boysData,method=\"pearson\"),digits=2)\n\n     x    y\nx 1.00 0.86\ny 0.86 1.00\n\n# This result is close to 1 so a strong positive relation is implied.\n\n# C2. Use ggpairs to plot the time spent and grade for\n# girls' and boys' datasets, respectively.\n\n# For the Girls' dataset:\nggpairs(\n  girlsData,\n  upper = list(wrap(\"cor\", size = 5)),\n  diag = list(continuous = \"densityDiag\"),\n)\n\n\n\n\n\n\n\n# For the Boys' dataset:\nggpairs(\n  boysData,\n  upper = list(wrap(\"cor\", size = 5)), \n  diag = list(continuous = \"densityDiag\"),\n)"
  },
  {
    "objectID": "posts/Module 7 Assignment/index.html",
    "href": "posts/Module 7 Assignment/index.html",
    "title": "Module 7 Assignment",
    "section": "",
    "text": "An Exercise in Simple and Multiple Regression!\n\n# LIS4273 - Module 7. Assignment\n# Robert Walsh\n# Professor Lingyao Li\n\n# Question A.\n\n# In this assignment's segment, we will use the following regression\n# equation  Y = a + bX +e\n\n# Y is the value of the dependent variable (Y),\n# what is being predicted or explained\n\n# a or Alpha, a constant; equals the value of Y when the value of X=0\n\n# b or Beta, the coefficient of X; the slope of the regression line;\n# how much Y changes for each one-unit change in X.\n\n# X is the value of the Independent variable (X),\n# what is predicting or explaining the value of Y\n\n# e is the error term; the error in predicting the value of Y,\n# given the value of X (it is not displayed in most regression equations).\n\n# The data in this assignment:\nx &lt;- c(16, 17, 13, 18, 12, 14, 19, 11, 11, 10)\ny &lt;- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)\n\n# A1. Define the relationship model between the independent\n# and the dependent variable.\n\n# 'x' is the value of the Independent variable (X),\n# what is predicting or explaining the value of 'y'.\n# 'y' is the value of the dependent variable (Y),\n# what is being predicted or explained.\n\n# To model the relationship between how one variable affects the other:\nmodel.x.y&lt;-lm(y~x,)\n# Create 'model.x.y' object to store results of.....\n# lm(Y~X), linear model: 'y' is predicted by 'x'\n\n# A2. Calculate the coefficients:\n# Print 'model.x.y' object.\nmodel.x.y\n\n\nCall:\nlm(formula = y ~ x)\n\nCoefficients:\n(Intercept)            x  \n     19.206        3.269  \n\n# Question B.\n\n# The following question is posted by Chi Yau (Links to an external site.)\n# the author of  R Tutorial With Bayesian Statistics Using Stan\n# (Links to an external site.) and his blog posting regarding\n# Regression analysis (Links to an external site.).\n\n# Apply the simple linear regression model (see the above formula)\n# for the data set called \"visit\" (see below), and estimate the\n# discharge duration if the waiting time since the last eruption\n# has been 80 minutes.\n\n#  &gt;head(visit) \n#  discharge  waiting \n# 1     3.600      79 \n# 2     1.800      54 \n# 3     3.333      74 \n# 4     2.283      62 \n# 5     4.533      85 \n# 6     2.883      55\n\nvisit&lt;-data.frame(\"discharge\"=c(3.600,1.800,3.333,2.283,4.533,2.883),\n                  \"waiting\"=c(79,54,74,62,85,55))\n\n# Employ the following formula lm(discharge~waiting,data=visit)\n\n# B1. Define the relationship model between the predictor\n# and the response variable.\n\n# The 'predictor' variable predicts the 'response' variable.\n# 'waiting' is the value of the Independent variable (X),\n# what is predicting or explaining the value of 'discharge'.\n# 'discharge' is the value of the dependent variable (Y),\n# what is being predicted or explained.\n\n# To model the relationship between how one variable affects the other:\ndischarge.lm&lt;-lm(discharge~waiting,data=visit)\n# Create 'discharge.lm' object to store results of.....\n# lm(discharge~waiting,data=visit), linear model:\n# 'discharge' is predicted by 'waiting'\n\n# B2. Extract the parameters of the estimated regression equation\n# with the coefficients function.\ncoeffs&lt;-coefficients(discharge.lm)\ncoeffs\n\n(Intercept)     waiting \n-1.53317418  0.06755757 \n\n# B3. Determine the fit of the eruption duration using\n# the estimated regression equation.\n\n# Create 'waitingTime' object and initialize to value of '80'.\nwaitingTime&lt;-80\n# Fit the discharge duration using the estimated regression equation.\ndischargeDuration&lt;-coeffs[1]+coeffs[2]*waitingTime\ndischargeDuration\n\n(Intercept) \n   3.871431 \n\n# Based on the linear regression model, if the waiting time since the\n# last discharge has been 80 minutes, we expect the next discharge duration\n# to last approximately 3.871431 minutes.\n\n# Question C.  Multiple regression\n\n# We will use a very famous datasets in R called mtcars. This dateset\n# was extracted from the 1974 Motor Trend US magazine, and comprises\n# fuel consumption and 10 aspects of automobile design and performance\n# for 32 automobiles (1973--74 models).\n\n# This data frame contain 32 observations on 11 (numeric) variables.\n\n# [, 1] mpg Miles/(US) gallon\n# [, 2] cyl Number of cylinders\n# [, 3] disp    Displacement (cu.in.)\n# [, 4] hp  Gross horsepower\n# [, 5] drat    Rear axle ratio\n# [, 6] wt  Weight (1000 lbs)\n# [, 7] qsec    1/4 mile time\n# [, 8] vs  Engine (0 = V-shaped, 1 = straight)\n# [, 9] am  Transmission (0 = automatic, 1 = manual)\n# [,10] gear    Number of forward gears\n\n# To call mtcars data in R\n# R comes with several built-in data sets, which are generally used\n# as demo data for playing with R functions. One of those datasets\n# build in R is mtcars.\n\n# In this question, we will use 4 of the variables found in mtcars\n# by using the following function\n# input &lt;- mtcars[,c(\"mpg\",\"disp\",\"hp\",\"wt\")]\n\n# C1. Examine the relationship Multi Regression Model as stated above\n# and its Coefficients using 4 different variables from mtcars\n# (mpg, disp, hp and wt).\n# Report on the result and explanation what does the multi regression\n# model and coefficients tell about the data.\ninput &lt;- mtcars[,c(\"mpg\",\"disp\",\"hp\",\"wt\")]\nprint(head(input))\n\n                   mpg disp  hp    wt\nMazda RX4         21.0  160 110 2.620\nMazda RX4 Wag     21.0  160 110 2.875\nDatsun 710        22.8  108  93 2.320\nHornet 4 Drive    21.4  258 110 3.215\nHornet Sportabout 18.7  360 175 3.440\nValiant           18.1  225 105 3.460\n\nlm(formula=mpg~disp+hp+wt,data=input)\n\n\nCall:\nlm(formula = mpg ~ disp + hp + wt, data = input)\n\nCoefficients:\n(Intercept)         disp           hp           wt  \n  37.105505    -0.000937    -0.031157    -3.800891  \n\ncat(\"The relationship multi regression model demonstrates that 'mpg' is \nthe 'response variable' being predicted by 'disp', 'hp', and 'wt' which\nare the 'predictor variables.' What is learned from the coefficients is that\n'disp' and 'hp' have coefficients close to 0 which means that they may relate\nin similar ways. The -3.8 coefficient for 'wt' means that as 'wt' increases,\n'mpg' decreases and as 'mpg' increases, 'wt' decreases. This demonstrates how\neach variable predicts or affects 'mpg' differently and to what magnitude. Each\npredictor variable is individually related to the response variable.\")\n\nThe relationship multi regression model demonstrates that 'mpg' is \nthe 'response variable' being predicted by 'disp', 'hp', and 'wt' which\nare the 'predictor variables.' What is learned from the coefficients is that\n'disp' and 'hp' have coefficients close to 0 which means that they may relate\nin similar ways. The -3.8 coefficient for 'wt' means that as 'wt' increases,\n'mpg' decreases and as 'mpg' increases, 'wt' decreases. This demonstrates how\neach variable predicts or affects 'mpg' differently and to what magnitude. Each\npredictor variable is individually related to the response variable."
  }
]